version: '3.8'

services:
  # VDS Backend Service
  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: chatbot-backend
    ports:
      - "8000:8000"
    environment:
      - VDS_DOMAIN=chat.mehhost.ru
      - API_GATEWAY_PORT=8000
      - JWT_SECRET=auto_generate
    volumes:
      - ./backend:/app/backend
      - ./logs:/app/logs
    networks:
      - chatbot-network
    depends_on:
      - db
    restart: unless-stopped

  # Local Inference Service (simulated for local testing)
  local-inference:
    build:
      context: .
      dockerfile: Dockerfile.inference
    container_name: chatbot-local-inference
    ports:
      - "8001:8001"
    environment:
      - LOCAL_INFERENCE_PORT=8001
      - RUST_ACCELERATION=true
    volumes:
      - ./local-inference:/app/local-inference
      - ./models:/app/models
    networks:
      - chatbot-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  # Database
  db:
    image: mysql:8.0
    container_name: chatbot-db
    ports:
      - "3306:3306"
    environment:
      MYSQL_ROOT_PASSWORD: rootpassword
      MYSQL_DATABASE: chatbot_db
      MYSQL_USER: chatbot_user
      MYSQL_PASSWORD: chatbot_password
    volumes:
      - db_data:/var/lib/mysql
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - chatbot-network
    restart: unless-stopped

  # Redis for caching and session storage
  redis:
    image: redis:7-alpine
    container_name: chatbot-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - chatbot-network
    restart: unless-stopped

  # Frontend
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    container_name: chatbot-frontend
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app/frontend
    networks:
      - chatbot-network
    restart: unless-stopped

  # Nginx as reverse proxy
  nginx:
    image: nginx:alpine
    container_name: chatbot-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/chatbot.conf:/etc/nginx/conf.d/default.conf
      - ./frontend/dist:/usr/share/nginx/html
    depends_on:
      - backend
      - frontend
    networks:
      - chatbot-network
    restart: unless-stopped

volumes:
  db_data:
  redis_data:

networks:
  chatbot-network:
    driver: bridge